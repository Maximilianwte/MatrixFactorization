{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.albertauyeung.com/post/python-matrix-factorization/\n",
    "class Matrix_Factorizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def read_matrices(self, size = \"medium\"):\n",
    "        # Read_Data: load ratings matrices from csv & numpy data. If data is not available run Pre-Processing first.\n",
    "        self.matrix_asFrame = pd.read_csv(f\"df_ratings_matrix_{size}.csv\")\n",
    "        self.ratings_matrix = np.load(\"ratings_matrix.npy\")\n",
    "        self.num_users, self.num_items = self.ratings_matrix.shape\n",
    "    def set_factorizer(self, k, alpha, beta, n):\n",
    "        # K - Latent Factors, Alpha - Learning rate, Beta - Regulation, N - Iterations \n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "    def train_model(self):\n",
    "        self.user_v = np.random.normal(size=(self.num_users, self.k))\n",
    "        self.item_v = np.random.normal(size=(self.num_items, self.k))\n",
    "        self.user_b = np.random.normal(size=(self.num_users, 1))\n",
    "        self.item_b = np.random.normal(size=(self.num_items, 1))\n",
    "        \n",
    "        user_v_derivateSum = np.zeros((self.num_users, self.k))\n",
    "        item_v_derivateSum = np.zeros((self.num_items, self.k))\n",
    "        user_b_derivateSum = np.zeros((self.num_users, 1))\n",
    "        item_b_derivateSum = np.zeros((self.num_items, 1))\n",
    "        \n",
    "        for i in range(0, self.n):\n",
    "            user_v_derivate, user_b_derivate = self.deriv(True)\n",
    "            user_v_derivateSum += np.square(user_v_derivate)\n",
    "            user_b_derivateSum += np.square(user_b_derivate)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Factorizer = Matrix_Factorizer()\n",
    "Factorizer.read_matrices(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 12,  1, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  1,  1,  1]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Factorizer.ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0421284   0.02213674  0.00979709 ...  0.0125502  -0.02691651\n",
      "   0.0096875 ]\n",
      " [ 0.02107111 -0.06575995 -0.03212653 ...  0.06479544  0.01856468\n",
      "   0.00330234]\n",
      " [-0.0271677  -0.02952448  0.02592381 ...  0.01417467  0.07002111\n",
      "   0.03658496]\n",
      " ...\n",
      " [ 0.00551752  0.03334524 -0.00650906 ...  0.06812171 -0.09660146\n",
      "  -0.03342977]\n",
      " [-0.0574518   0.06740997  0.09852109 ... -0.03874068  0.02776267\n",
      "  -0.03439679]\n",
      " [-0.07220482  0.06075213  0.00388906 ...  0.0716209   0.03118613\n",
      "   0.03083413]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\studsmi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: RuntimeWarning: overflow encountered in multiply\n",
      "C:\\Users\\studsmi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:68: RuntimeWarning: overflow encountered in multiply\n",
      "C:\\Users\\studsmi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: RuntimeWarning: invalid value encountered in add\n",
      "C:\\Users\\studsmi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: RuntimeWarning: overflow encountered in double_scalars\n",
      "C:\\Users\\studsmi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:68: RuntimeWarning: invalid value encountered in add\n",
      "C:\\Users\\studsmi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\studsmi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = nan\n",
      "Iteration: 20 ; error = nan\n",
      "Iteration: 30 ; error = nan\n",
      "\n",
      "P x Q:\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "\n",
      "Global bias:\n",
      "2.202527924750147\n",
      "\n",
      "User bias:\n",
      "[        nan -0.76686445 -0.86644276 -0.92929727         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.57447787         nan -0.58107194         nan         nan         nan\n",
      "         nan         nan         nan         nan -1.05563419         nan\n",
      "  0.20230316         nan -0.84642521 -0.57277156 -0.56684454 -0.56445013\n",
      " -0.47745443         nan         nan -0.57056526         nan -0.56883658\n",
      "  0.50247848         nan         nan         nan  0.07049419 -0.09807713\n",
      "         nan         nan -0.54793329 -0.56666555 -0.85352619         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.44779939 -0.38889758         nan         nan -0.80268251         nan\n",
      "  0.07436927 -0.8150429   0.37304246  0.72240501 -0.77378862         nan\n",
      " -0.44709725         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  0.96666849         nan         nan\n",
      " -0.77191115  2.32809481  0.83914918         nan -0.11494176 -0.76967985\n",
      "         nan         nan         nan         nan         nan  0.29013023\n",
      "  0.03292665 -0.54636706 -0.07248731         nan -0.13094015 -0.10049305\n",
      "         nan         nan -0.32327271 -0.5693176   1.98204832  0.73080623\n",
      "         nan -0.86369633         nan -0.77196528  0.38240594         nan\n",
      "         nan         nan  0.49186338         nan         nan -0.09818991\n",
      "  0.29865302 -0.63334153         nan         nan         nan         nan\n",
      "  0.18646574         nan         nan         nan -1.01207526         nan\n",
      " -0.76543405         nan         nan -0.4512123          nan -0.80444068\n",
      "  0.09056003         nan -0.43987928         nan         nan -0.77207536\n",
      " -0.87034315         nan         nan -0.57850363 -0.86997692 -0.09626955\n",
      " -0.08708548 -0.36926264 -0.57139586         nan         nan         nan\n",
      "         nan         nan         nan -0.53342011         nan -0.38181694\n",
      "         nan         nan -0.43181923         nan -0.86223156         nan\n",
      " -0.56195098 -0.71821965         nan         nan -0.12489934 -0.101645\n",
      " -0.79702728 -0.72533054         nan         nan -0.06661481 -0.4710211\n",
      "  1.25289942         nan -0.77056116 -0.76551957         nan  0.84261112\n",
      " -0.33235818 -0.6561026  -0.92646791         nan -0.33818964 -0.58060905\n",
      " -0.5339715  -1.03960273  1.28140353         nan         nan         nan\n",
      " -0.45000186         nan -0.15455139         nan         nan -0.22331547\n",
      "  0.19451948         nan         nan -0.38600788         nan         nan\n",
      "         nan]\n",
      "\n",
      "Item bias:\n",
      "[nan nan nan ... nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "Factorizer.set_factorizer(25, 0.1, 0.01, 30)\n",
    "training_process = Factorizer.train()\n",
    "print()\n",
    "print(\"P x Q:\")\n",
    "print(Factorizer.full_matrix())\n",
    "print()\n",
    "print(\"Global bias:\")\n",
    "print(Factorizer.b)\n",
    "print()\n",
    "print(\"User bias:\")\n",
    "print(Factorizer.b_u)\n",
    "print()\n",
    "print(\"Item bias:\")\n",
    "print(Factorizer.b_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
