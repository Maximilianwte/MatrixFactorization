{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy.sparse as sparse\nimport os\nimport implicit\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Implicit:\n    def __init__(self, seed = 941, environment = \"offline\"):\n        self.seed = seed\n        self.not_testable = 0\n        \n        if environment == \"kaggle\":\n            self.read_matrices_timesplit(\"/kaggle/input/\")\n        else:\n            self.read_matrices_timesplit(\"../\")\n        \n    def read_matrices_timesplit(self, path):\n        self.training_set_csr = sparse.load_npz(f\"{path}/ratings_matrix_csr.npz\")\n        self.training_set_csr = self.training_set_csr.T\n        self.training_set_coo = sparse.load_npz(f\"{path}/ratings_matrix_coo.npz\")\n        self.training_set_coo = self.training_set_coo.T\n        \n        self.user_ids = np.load(f\"{path}/user_ids.npy\")\n        self.content_ids = np.load(f\"{path}/content_ids.npy\")\n        \n        self.test_set = pd.read_pickle(f\"{path}/test_set.pkl\", compression=\"zip\")\n        self.data_popularity = np.load(f\"{path}/popularity_data_mayjuly19.npy\", allow_pickle=True)\n\n        self.num_items, self.num_users = self.training_set_csr.shape\n    \n    def alternating_least_squares(self, iterations, factors, i_lambda, alpha):\n        self.model = implicit.als.AlternatingLeastSquares(factors=factors, regularization = i_lambda, iterations = iterations)\n        self.model.fit((self.training_set_csr*alpha).astype('double'))\n                \n    def logistic_factorization(self, iterations, factors, i_lambda, learning_parameter, alpha):\n        self.model = implicit.lmf.LogisticMatrixFactorization(factors, learning_parameter, i_lambda, iterations = iterations)\n        self.model.fit((self.training_set_coo*alpha).astype('double'))\n        \n    def predict_user_byIndex(self, index):\n        return self.model.item_factors.dot(self.model.user_factors[index].T)\n    \n    def predict_user_byId(self, userId):\n        index = np.where(self.user_ids==userId)[0][0]\n        return self.model.item_factors.dot(self.model.user_factors[index].T)\n    \n    def predict_recommendations(self, userId):\n        vector = self.predict_user_byId(userId)\n        vector_sorted = np.sort(vector, kind=\"mergesort\")\n        \n        recommendations = list()\n        for i in range(5):\n            recommendations.append(np.where(vector==vector_sorted[i])[0][0])\n            \n        return recommendations\n        \n    def get_user_vectors(self, users):\n        user_dict = dict()\n        \n        for i in range(len(users)):\n            try:\n                user_indx = np.where(self.user_ids==users[i])[0][0]\n                user_dict[users[i]] = self.predict_user_byIndex(user_indx)\n            except:\n                self.not_testable += 1\n                \n        return user_dict\n    \n    def get_user_vectors_sorted(self, user_dict):\n        user_dict_sorted = dict()\n        \n        for key in user_dict:\n            user_dict_sorted[key] = np.sort(user_dict[key], kind=\"mergesort\")[:5000]\n                \n        return user_dict_sorted\n    \n    def get_rank(self, item, user_vector, user_vector_sorted):\n        item_indx = np.where(self.content_ids==item)[0][0]\n        \n        prob = user_vector[item_indx]\n        return np.where(user_vector_sorted==prob)[0][0]\n\n    def expected_percentile_ranking(self):\n        accuracy = list()\n        mar = 0   \n        self.not_testable = 0        \n        users = self.test_set.idUser.values\n        contents = self.test_set.fullId.values\n        \n        user_dict = self.get_user_vectors(self.test_set.idUser.unique())\n        user_dict_sorted = self.get_user_vectors_sorted(user_dict)\n        \n        for i in range(len(users)):\n            try:\n                accuracy.append(self.get_rank(contents[i], user_vector = user_dict[users[i]],user_vector_sorted = user_dict_sorted[users[i]]) / 5000)\n            except:\n                pass\n            \n            if i % 84650 == 0:\n                print(f\"Solved iteration: {i}. That's approximately {np.round((i/len(contents))*100,2)}%.\")\n\n        mar = np.mean(accuracy)\n            \n        return mar, accuracy\n    \n    def calculate_epr_popularity(self):\n        accuracy = list()\n        mar = 0        \n        users = self.test_set.idUser.values\n        contents = self.test_set.fullId.values\n        \n        data_popularity_sorted = np.sort(self.data_popularity, kind=\"mergesort\")\n        \n        for i in range(len(users)):\n            try:\n                accuracy.append(self.get_rank(contents[i], user_vector = self.data_popularity,user_vector_sorted = data_popularity_sorted) / 5000)\n            except:\n                pass\n\n            if i % step == 0:\n               print(f\"Solved iteration: {i}. That's approximately {np.round((i/len(contents))*100,2)}%.\")\n\n        mar = np.mean(accuracy)\n            \n        return mar, accuracy ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Studio:\n    def __init__(self, seed, env, factorizer = \"\"):\n        self.counter = 0\n        self.seed = seed\n        self.env = env\n        \n        if factorizer == \"\":\n            self.MF = Implicit(seed, env)\n        else:\n            self.MF = factorizer\n            \n    def save_model(self, user_vec, item_vec, parameters = \"\"):\n        np.save(f\"user_vec_{self.counter}_{parameters}\", user_vec)\n        np.save(f\"item_vec_{self.counter}_{parameters}\", item_vec)\n        self.counter += 1\n        \n    def run_test_als(self, v_iterations, v_factors, v_lambdas, v_alphas):\n        model_acc = list()\n        \n        for it in v_iterations:\n            for factor in v_factors:\n                for in_lambda in v_lambdas:\n                    for alpha in v_alphas:\n                       # print(f\"Starting Iteration: iterations-{it}_factors-{factor}_lambda-{in_lambda}_alpha-{alpha}\")\n                        self.MF.alternating_least_squares(iterations = it, factors = factor, i_lambda = in_lambda, alpha = alpha)\n                        mar, accuracy = self.MF.expected_percentile_ranking()\n                        \n                        #self.save_model(self.MF.model.user_factors, self.MF.model.item_factors, f\"{time.time()}_iterations-{it}_factors-{factor}_lambda-{in_lambda}_alpha-{alpha}\")\n                        #model_acc.append([f\"model_als-iterations-{it}_factors-{factor}_lambda-{in_lambda}_alpha-{alpha}\", mar, accuracy])                        \n                        print(f\"Finishing up Iteration: iterations-{it}_factors-{factor}_lambda-{in_lambda}_alpha-{alpha}. Reported MAR: {mar}.\")\n        #np.save(f\"model_acc_{time.time()}\", model_acc)              \n        return model_acc\n    \n    def run_test_log(self, v_iterations, v_factors, v_lambdas, v_learning, v_alpha):\n        model_acc = list()\n\n        for in_alpha in v_alpha:\n            for it in v_iterations:\n                for factor in v_factors:\n                    for in_lambda in v_lambdas:\n                        for in_learning in v_learning:\n                           # print(f\"Starting Iteration: iterations-{it}_factors-{factor}_lambda-{in_lambda}_learning_parameter-{in_learning}_alpha-{in_alpha}\")\n                            self.MF.logistic_factorization(iterations = it, factors = factor, i_lambda = in_lambda, learning_parameter = in_learning, alpha = in_alpha)\n                            mar, accuracy = self.MF.expected_percentile_ranking()\n\n                            #self.save_model(self.MF.model.user_factors, self.MF.model.item_factors, f\"{time.time()}_iterations-{it}_factors-{factor}_lambda-{in_lambda}_learning_parameter-{learning_parameter}\")\n                           # model_acc.append([f\"model_als-iterations-{it}_factors-{factor}_lambda-{in_lambda}_learning_parameter-{in_learning}_alpha-{in_alpha}\", mar, accuracy])                        \n                            print(f\"Finishing up Iteration: iterations-{it}_factors-{factor}_lambda-{in_lambda}_learning_parameter-{in_learning}_alpha-{in_alpha}. Reported MAR: {mar}.\")\n        #np.save(f\"model_acc_{time.time()}\", model_acc)              \n        return model_acc\n                        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implicit Matrix Factorization Model, Koren 2008.\nModel_Implicit = Implicit(941, \"kaggle\")\n#Model_Implicit.alternating_least_squares(iterations = 20, factors = 30, i_lambda = 0.01, alpha = 15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Matrix Factorization Model, Johnson 2014.\nLogistic = Implicit(941, \"kaggle\")\n#Logistic.logistic_factorization(iterations = 40, factors = 100, i_lambda = 0.01, learning_parameter = 0.1, alpha = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the Mean Accuracy Ranking for the popularity data.\nmar, accuracy = Model_Implicit.calculate_epr_popularity()\nmar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Studio class is designed to run multiple tests at ones.\nAnalysis = Studio(941, \"kaggle\", Model_Implicit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_accuracy = Analysis.run_test_als(v_iterations = [40], v_factors = [20,30,40,60,80,100,150,200,300], v_lambdas = [0.01], v_alphas = [15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Analysis = Studio(941, \"kaggle\", Logistic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_accuracy = Analysis.run_test_log(v_iterations = [40], v_factors = [40], v_lambdas = [0.01], v_learning = [0.1], v_alpha = [1,10,40])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing the trainings matrix with a specific user. Input: idUser and idContent\nidUser = 298\nidContent = \"1_16946\"\nindexUser = np.where(Model_Implicit.user_ids==idUser)[0][0]\nindexContent = np.where(Model_Implicit.content_ids==idContent)[0][0]\nModel_Implicit.training_set_csr.toarray()[indexContent][indexUser]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nALS, 5000 Products:\nFinishing up Iteration: iterations-40_factors-15_lambda-0.01_alpha-15. Reported MAR: 0.5007135416666667.\nFinishing up Iteration: iterations-40_factors-30_lambda-0.01_alpha-15. Reported MAR: 0.4913303225806451.\nFinishing up Iteration: iterations-40_factors-40_lambda-0.01_alpha-15. Reported MAR: 0.506864739884393.\nFinishing up Iteration: iterations-40_factors-40_lambda-0.01_alpha-15. Reported MAR: 0.520812426035503.\nFinishing up Iteration: iterations-40_factors-60_lambda-0.01_alpha-15. Reported MAR: 0.4761294117647059.\nFinishing up Iteration: iterations-40_factors-80_lambda-0.01_alpha-15. Reported MAR: 0.45779899497487436.\nFinishing up Iteration: iterations-40_factors-100_lambda-0.01_alpha-15. Reported MAR: 0.4202738498789346.\nFinishing up Iteration: iterations-40_factors-150_lambda-0.01_alpha-15. Reported MAR: 0.4120840476190476.\nFinishing up Iteration: iterations-40_factors-200_lambda-0.01_alpha-15. Reported MAR: 0.4197281262646702.\nFinishing up Iteration: iterations-40_factors-300_lambda-0.01_alpha-15. Reported MAR: 0.4236005339028297.\n\n\nLOG, 5000 Products:\nFinishing up Iteration: iterations-40_factors-20_lambda-0.01_learning_parameter-0.1_alpha-1. Reported MAR: 0.5301564245810055.\nFinishing up Iteration: iterations-40_factors-30_lambda-0.01_learning_parameter-0.1_alpha-1. Reported MAR: 0.46028966725043785.\nFinishing up Iteration: iterations-40_factors-30_lambda-0.01_learning_parameter-0.01_alpha-1. Reported MAR: 0.4983864004317323.\nFinishing up Iteration: iterations-40_factors-40_lambda-0.01_learning_parameter-0.01_alpha-1. Reported MAR: 0.4961798309859155.\nFinishing up Iteration: iterations-40_factors-40_lambda-0.01_learning_parameter-0.1_alpha-1. Reported MAR: 0.462060736196319.\nFinishing up Iteration: iterations-40_factors-60_lambda-0.01_learning_parameter-0.01_alpha-1. Reported MAR: 0.5014183713355049.\nFinishing up Iteration: iterations-40_factors-60_lambda-0.01_learning_parameter-0.01_alpha-1. Reported MAR: 0.5008075784487863.\nFinishing up Iteration: iterations-40_factors-80_lambda-0.01_learning_parameter-0.01_alpha-1. Reported MAR: 0.4905897535667964\nFinishing up Iteration: iterations-40_factors-100_lambda-0.01_learning_parameter-0.1_alpha-1. Reported MAR: 0.5021024330900243\nFinishing up Iteration: iterations-40_factors-150_lambda-0.01_learning_parameter-0.1_alpha-1. Reported MAR: 0.4807635846372688\nFinishing up Iteration: iterations-40_factors-200_lambda-0.01_learning_parameter-0.01_alpha-1. Reported MAR: 0.51474453125\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idUser = 298\nidContent = \"1_16946\"\nindexUser = np.where(Model_Implicit.user_ids==idUser)[0][0]\nindexContent = np.where(Model_Implicit.content_ids==idContent)[0][0]\nModel_Implicit.model.explain(indexUser, Model_Implicit.training_set_csr, indexContent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def explain(userId):\n    recommendation = Model_Implicit.predict_recommendations(userId)[0]\n    \n    return Model_Implicit.model.similar_items(recommendation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model_Implicit.predict_recommendations(298)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explain(298)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model_Implicit.predict_user_byId(298)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_accuracy = Analysis.run_test_als(v_iterations = [40], v_factors = [15,20,30,40,60,80,100,150,200,300], v_lambdas = [0.01], v_alphas = [15])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}