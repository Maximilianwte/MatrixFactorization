{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing v3.0\n",
    "### Nutzung: Import der Daten, Cleanup, Generierung der Rating Matrix, Testdatensatz, Popularity Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import heapq\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pre_Processer:\n",
    "    def __init__(self):\n",
    "        self.contentType = {\"Statistic\": \"0\", \"Statista-Dossier\": \"1\", \"external Report\": \"2\", \"Industry Report\": \"3\"}\n",
    "        \n",
    "    def read_data_full(self):\n",
    "        self.data_users = pd.read_csv(\"../StatistaUsers10000.csv\")\n",
    "        self.data_tracking = pd.read_csv(\"../StatistaTracking10000.csv\")\n",
    "\n",
    "        return self.data_users, self.data_tracking\n",
    "    \n",
    "    def read_pickles(self):\n",
    "        self.training_set = pd.read_pickle(f\"../training_set.pkl\", compression=\"zip\")\n",
    "        self.test_set = pd.read_pickle(f\"../test_set.pkl\", compression=\"zip\")\n",
    "        \n",
    "        return self.training_set, self.test_set\n",
    "    \n",
    "    def generate_fullID_vectorized(self, subType, contentId):\n",
    "        array = []\n",
    "        for i in range(len(subType)):\n",
    "            array.append((self.contentType[subType[i]] if subType[i] in self.contentType else \"4\") + \"_\" + str(contentId[i]))\n",
    "\n",
    "        return array\n",
    "    \n",
    "    def clean_tracking(self, tracking_data, start_year = 2017, end_date = None):\n",
    "        data = tracking_data[tracking_data.idContent != 0]\n",
    "        data = data.iloc[:, 0:6]\n",
    "        data = data[data.year >= start_year]\n",
    "        data[\"date\"] = data['year'].astype(str) + \"-\" + data['month'].astype(str) + \"-\" + data[\"day\"].astype(str)\n",
    "        if end_date != None:\n",
    "            data = data[data.date <= end_date]\n",
    "        data[\"fullId\"] = self.generate_fullID_vectorized(data[\"contentSubType\"].values, data[\"idContent\"].values)\n",
    "\n",
    "        self.data_tracking = data\n",
    "        data.to_pickle(f\"../data_tracking.pkl\", compression=\"zip\")\n",
    "        return data\n",
    "    \n",
    "    def create_timesplit(self, data, date):\n",
    "        self.training_set = data[data.date < date]\n",
    "        self.test_set = data[data.date >= date]\n",
    "        \n",
    "        self.training_set.to_pickle(f\"../training_set.pkl\", compression=\"zip\")\n",
    "        self.test_set.to_pickle(f\"../test_set.pkl\", compression=\"zip\")\n",
    "        return self.training_set, self.test_set\n",
    "    \n",
    "    def generate_popularity_vector(self, data):\n",
    "        data = pd.DataFrame(data[\"fullId\"])\n",
    "        data[\"views\"] = np.ones([len(data[\"fullId\"]),1])\n",
    "        data = data.groupby(by=[\"fullId\"]).sum().reset_index()\n",
    "        data = data.sort_values(by=[\"views\"], ascending=False)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def create_matrices(self, training_set, test_set):\n",
    "        # training_set\n",
    "        frame = training_set[[\"idUser\", \"fullId\"]]\n",
    "        frame[\"views\"] = np.ones([len(frame[\"fullId\"]),1])\n",
    "        frame = frame.groupby(by=[\"idUser\", \"fullId\"]).sum().reset_index()\n",
    "\n",
    "        user = list(np.sort(frame.idUser.unique()))\n",
    "        content = list(np.sort(frame.fullId.unique()))\n",
    "        views = list(frame.views)\n",
    "        rows = frame.idUser.astype('category').cat.codes \n",
    "        cols = frame.fullId.astype('category').cat.codes \n",
    "        \n",
    "        self.sparsity_ofdata = 1 - (len(views) / (len(content) * len(user)))\n",
    "\n",
    "        matrix_csr = sparse.csr_matrix((views, (rows, cols)), shape=(len(user), len(content)))\n",
    "        matrix_coo = sparse.coo_matrix((views, (rows, cols)), shape=(len(user), len(content)))\n",
    "        sparse.save_npz(f\"../ratings_matrix_csr\", matrix_csr, compressed=True)\n",
    "        sparse.save_npz(f\"../ratings_matrix_coo\", matrix_coo, compressed=True)\n",
    "\n",
    "        training_set = frame\n",
    "        self.training_set.to_pickle(f\"../training_set_aggregated.pkl\", compression=\"zip\")\n",
    "        \n",
    "        self.matrix_csr = matrix_csr\n",
    "        self.matrix_coo = matrix_coo\n",
    "        \n",
    "        self.user = user\n",
    "        self.content = content\n",
    "        self.views = views\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        \n",
    "        np.save(\"../user_ids\", user)\n",
    "        np.save(\"../content_ids\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the object.\n",
    "Data = Pre_Processer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the full pre-processing run.\n",
    "user_data, data_tracking = Data.read_data_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tracking = Data.clean_tracking(data_tracking, start_year=2017, end_date = \"2019-7-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set = Data.create_timesplit(data_tracking, \"2019-7-1\")\n",
    "Data.create_matrices(training_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate & save the popularity data vector.\n",
    "popularity_data = training_set[training_setining_set.date > \"2019-4-30\"]\n",
    "popularity_data = Data.generate_popularity_vector(popularity_data)\n",
    "np.save(\"../popularity_data\", popularity_data.fullId.values[:5000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
